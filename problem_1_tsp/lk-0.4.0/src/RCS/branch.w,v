head	1.17;
access;
symbols
	zero-four-zero:1.17;
locks
	neto:1.17;


1.17
date	98.05.21.20.45.45;	author neto;	state Exp;
branches;
next	1.16;

1.16
date	98.05.21.19.50.11;	author neto;	state Exp;
branches;
next	1.15;

1.15
date	98.05.21.19.29.35;	author neto;	state Exp;
branches;
next	1.14;

1.14
date	95.11.17.16.06.00;	author neto;	state Exp;
branches;
next	1.13;

1.13
date	95.04.07.16.18.25;	author neto;	state Exp;
branches;
next	1.12;

1.12
date	95.04.07.15.44.16;	author neto;	state Exp;
branches;
next	1.11;

1.11
date	95.04.03.17.01.42;	author neto;	state Exp;
branches;
next	1.10;

1.10
date	95.03.23.13.54.08;	author neto;	state Exp;
branches;
next	1.9;

1.9
date	95.01.24.12.59.42;	author neto;	state Exp;
branches;
next	;


desc
@branching according to Volgenant and Jonker.
@


1.17
log
@Now this compiles in the strict GCC environment that I like.
@
text
@@@i webdefs.w
@@i copyrt.w
@@i types.w

{\obeylines
$Log: branch.w,v $
Revision 1.16  1998/05/21 19:50:11  neto
Excised Wayne Hayes's Heap stuff, replacing it with dict stuff.

}

@@*Branching heuristics.
We branch according to the rules specified by Volgenant and Jonker.

The outline of this module is as follows.

@@c
#include <stdio.h>
#include <stdlib.h>
#include <stddef.h>
#include <assert.h>
#include "hk.h"
#include "memory.h"
#include "dict.h"
#include "branch.h"

@@<Type definitions@@>@@;
@@<Module-level variables@@>@@;
@@<Subroutines@@>@@;

@@ The exported interface is contained in the {\tt branch.h} header file,
which has the following form.

@@(branch.h@@>=
#if !defined(_BRANCH_H_)
#define _BRANCH_H_
@@<Module headers required for the interface@@>@@;
@@<Exported subroutines@@>@@;
#endif

@@ Work space.
@@<Type definitions@@>=
typedef struct {
	@@<Workspace fields@@>@@;
} branch_vertex_t;

@@
@@<Module-level variables@@>=
static branch_vertex_t **bv;
static int n, p;
static unsigned long seq_num;

@@ Setup and cleanup routines.  We get passed the number of cities and
the number of parallel teams.
@@<Subroutines@@>=
void
branch_setup( const int num_cities, const int num_teams )
{
	int i;
	n = num_cities;
	p = num_teams;
	seq_num = 0;

	bv = new_arr_of( branch_vertex_t *,p);	
	for (i=0;i<p;i++) {
		bv[i] = new_arr_of( branch_vertex_t ,n);	
	}
}

void
branch_cleanup(void)
{
	int i;
	for (i=0;i<p;i++) {
		free_mem(bv[i]);
	}
	free_mem(bv);
}

@@
@@<Exported subroutines@@>=
void branch_setup( const int num_cities, const int num_teams );
void branch_cleanup(void);

@@
If the given 1-tree is a tour, then return 1.    Otherwise,
branch according to Volgenant and Jonker rules and return 0.

@@<Subroutines@@>=
int
branch(dict_t *tasks,double lower_bound, search_node_t *bbnode,
	int team_num, edge_list_t *edge, onetree_node_t *onetree,
	double *lambda)
{
	branch_vertex_t *v = bv[team_num];
	int top, source, dest1, dest2;

	@@<Find the cycle of the 1-tree@@>@@;
	if ( top == n-1 ) /* It's a tour */
		return 1;
	
	@@<Find |source|, a good vertex to branch at@@>@@;
	@@<Find |dest1|, and |dest2|, destinations to associated with |source|@@>@@;
	@@<Branch using |source|, |dest1|, and |dest2|@@>@@;
	return 0;
}

@@
@@<Exported subroutines@@>=
int
branch(dict_t *tasks,double lower_bound, search_node_t *bbnode,
	int team_num, edge_list_t *edge, onetree_node_t *onetree,
	double *lambda);

@@ We need to include \file{dict.h} in our interface definition.
@@<Module headers required for the interface@@>=
#include "dict.h"

@@ We find the nodes of the cycle in the 1-tree by performing a depth-first
search beginning at vertex $n-1$.  
We use the |work| fields in a stack-like fashion.

@@<Workspace fields@@>=
int work;
int visited;
int edge_used;
edge_list_t *e;

@@  When the search is completed, the indices of the vertices on
the cycle are stored in the |work| fields in positions 0 through |top| of the 
|v| array.

@@<Find the cycle of the 1-tree@@>=
{ 	int i;

for (i=0;i<n;i++) {
	v[i].visited = 0;
	v[i].edge_used = 0;
}

top = 0;
v[0].work = n-1;
v[0].e = onetree[n-1].edges;
while ( top >= 0 ) {
	const int i = v[top].work;
	const edge_list_t *e = v[top].e;
	v[i].visited = 1;
	if ( e == NULL ) top--;
	else {
		const int dest = (e->e.from == i)? e->e.to : e->e.from;
		v[top].e = (e->e.from == i)? e->from_next : e->to_next;
		if ( !v[e-edge].edge_used ) {
			v[e-edge].edge_used = 1;
			if ( dest == n-1 ) break;
			if ( !v[dest].visited ) {
				top++;
				v[top].work = dest;
				v[top].e = onetree[dest].edges;
			}
		}
	}
}
}




@@ We follow the guidlines set by Volgenant and Jonker. 

First we find |source|, a point on the cycle in the 1-tree with
degree at least 3 in the 1-tree.  
We prefer that |source| be incident to a fixed in edge.
If there is still a choice, we prefer |source| to have as low a 
degree as possible.

@@<Find |source|, a good vertex to branch at@@>=
{	int i;
	source = -1;
	for (i=0;i<=top;i++) { const int w = v[i].work;
		if ( onetree[w].degree_less2 > 0 ) {
			if ( source == -1 ) source = w;
			else if ( onetree[source].a_fixed_in_dest == -1 
				&& onetree[w].a_fixed_in_dest != -1 ) source = w;
			else if ( onetree[source].degree_less2 > onetree[w].degree_less2 ) source = w;
		}
	}
}

@@  We find |dest1| and |dest2| such that these are destinations of
edges from |source| which are not fixed in.  

If posssible, we take
|dest1| to not be on the cycle in the 1-tree.  To determine this property,
we add one more working field.

@@<Workspace fields@@>=
int on_cycle;

@@ First we determine which vertices are on the cycle.

Then we scan the edges incident upon |source|, skipping the single
fixed in edge (identified by the |a_fixed_in_dest| field of the
|onetree| array) if it exists.


@@<Find |dest1|, and |dest2|, destinations to associated with |source|@@>=
{	int i;
	edge_list_t *e;
	for (i=0;i<n;i++) v[i].on_cycle = 0;
	for (i=0;i<=top;i++) v[v[i].work].on_cycle = 1;

	dest1= dest2=-1;
	for ( e=onetree[source].edges ; e ; ) {
		const int dest = e->e.from == source ? e->e.to : e->e.from;
		edge_list_t *next = e->e.from == source ? e->from_next : e->to_next;
		if ( dest != onetree[source].a_fixed_in_dest ) {
			if ( dest1 == -1 ) dest1 = dest;
			else if ( v[dest1].on_cycle && !v[dest].on_cycle  ) dest2 = dest1, dest1=dest;
			else dest2 = dest;
		}
		e = next;
	}
}

@@ Now we can branch according to the rules given by Volgenant and Jonker.

Let |e1 == (source,dest1)| and |e2==(source,dest2)|.
Suppose the included and excluded sets of edges defined by |bbnode| are 
$S=(I,E)$.

Then create the following three new supbroblems:
$S1=(I \cup \{ e1, e2\},E), 
S2=(I \cup \{ e1\},E \cup \{e2\}), 
S3=(I ,E \cup \{e1\})$.
If there is a fixed in edge incident upon |source|, then we don't generate
$S1$.

Generate $S3$, then $S2$ then $S1$ so that when relying on a depth-first
selection rule, the most-constrained node is examined first.  This is
done so that tours are found more quickly.

@@<Branch using |source|, |dest1|, and |dest2|@@>=
{
	search_node_t *s1b, *s2a, *s2b, *s3; 
	int i, bbnode_num = bbnode ? bbnode->node_num : 0;
	extern unsigned long count_subproblem;
	const int most_constrained_last = 0;

	s2a = new_of(search_node_t);
	s2a->in_out = FIXED_IN;
	s2a->e.from = source;
	s2a->e.to = dest1;
	s2a->parent = (search_node_t *)bbnode;
	{ search_node_t *po;	
		/* Thread the |from_next_in| and |to_next_in| fields */
		for ( po = (search_node_t *)bbnode; po ; po = po->parent )
			if ( po->in_out == FIXED_IN && 
				(po->e.from == source || po->e.to == source) ) break;
		s2a->from_next_in = po;
		for ( po = (search_node_t *)bbnode; po ; po = po->parent )
			if ( po->in_out == FIXED_IN && 
				(po->e.from == dest1 || po->e.to == dest1) ) break;
		s2a->to_next_in = po;
	}

	if ( most_constrained_last ) {
		@@<Generate S3@@>@@;
		@@<Generate S2@@>@@;
		@@<Generate S1@@>@@;
	} else {
		@@<Generate S1@@>@@;
		@@<Generate S2@@>@@;
		@@<Generate S3@@>@@;
	}
}

@@
@@<Generate S1@@>=
	if ( onetree[source].a_fixed_in_dest == -1 ) { /* Generate S1 */
		s1b = new_of(search_node_t);
		s1b->in_out = FIXED_IN;
		s1b->e.from = source;
		s1b->e.to = dest2;
		s1b->parent = s2a;
		{ search_node_t *po;	
			/* Thread the |from_next_in| and |to_next_in| fields */
			for ( po = (search_node_t *)bbnode; po ; po = po->parent )
				if ( po->in_out == FIXED_IN && 
					(po->e.from == source || po->e.to == source) ) break;
			s1b->from_next_in = po;
			for ( po = (search_node_t *)bbnode; po ; po = po->parent )
				if ( po->in_out == FIXED_IN && 
					(po->e.from == dest2 || po->e.to == dest2) ) break;
			s1b->to_next_in = po;
		}
		s1b->lower_bound = lower_bound;
		s1b->lambda = new_arr_of(double,n);
		for (i=0;i<n;i++) s1b->lambda[i] =  lambda[i];
		s1b->parent_num = bbnode_num;
		s1b->alpha = 0.0;
		s1b->seq_num = ++seq_num;
		dict_insert(tasks,s1b);
		count_subproblem++;
	}


@@
@@<Generate S2@@>=
	s2b = new_of(search_node_t);	/* Generate S2 */
	s2b->in_out = FIXED_OUT;
	s2b->e.from = source;
	s2b->e.to = dest2;
	s2b->parent = s2a;
	s2b->lower_bound = lower_bound;
	s2b->lambda = new_arr_of(double,n);
	for (i=0;i<n;i++) s2b->lambda[i] =  lambda[i];
	s2b->parent_num = bbnode_num;
	s2b->alpha = 0.0;
	s2b->seq_num = ++seq_num;
	{ search_node_t *po;	
		/* Thread the |from_next_out| and |to_next_out| fields */
		for ( po = (search_node_t *)bbnode; po ; po = po->parent )
			if ( po->in_out == FIXED_OUT && 
				(po->e.from == source || po->e.to == source) ) break;
		s2b->from_next_out = po;
		for ( po = (search_node_t *)bbnode; po ; po = po->parent )
			if ( po->in_out == FIXED_OUT && 
				(po->e.from == dest2 || po->e.to == dest2) ) break;
		s2b->to_next_out = po;
	}
	dict_insert(tasks,s2b);
	count_subproblem++;

@@
@@<Generate S3@@>=
	s3 = new_of(search_node_t);	/* Generate S3 */
	s3->in_out = FIXED_OUT;
	s3->e.from = source;
	s3->e.to = dest1;
	s3->parent = (search_node_t *)bbnode;
	s3->lower_bound = lower_bound;
	s3->lambda = new_arr_of(double,n);
	for (i=0;i<n;i++) s3->lambda[i] =  lambda[i];
	{ search_node_t *po;	
		/* Thread the |from_next_out| and |to_next_out| fields */
		for ( po = (search_node_t *)bbnode; po ; po = po->parent )
			if ( po->in_out == FIXED_OUT && 
				(po->e.from == source || po->e.to == source) ) break;
		s3->from_next_out = po;
		for ( po = (search_node_t *)bbnode; po ; po = po->parent )
			if ( po->in_out == FIXED_OUT && 
				(po->e.from == dest1 || po->e.to == dest1) ) break;
		s3->to_next_out = po;
	}
	s3->parent_num = bbnode_num;
	s3->alpha = 0.0;
	s3->seq_num = ++seq_num;
	dict_insert(tasks,s3);
	count_subproblem++;

@


1.16
log
@Excised Wayne Hayes's Heap stuff, replacing it with dict stuff.
@
text
@d6 4
a9 1
$Log$
d22 1
a22 1
#include "tsp.h"
d25 1
d35 3
d39 1
d80 4
d91 3
a93 3
branch(dict_t *tasks,const double lower_bound, const search_node_t *bbnode,
	const int team_num, const edge_list_t *edge, const onetree_node_t *onetree,
	const double *lambda)
d110 8
a117 3
int branch(dict_t *tasks, const double lower_bound, const search_node_t *bbnode,
	const int team_num, const edge_list_t *edge, const onetree_node_t *onetree,
	const double lambda);
@


1.15
log
@Fixed up standard CWEB thingies and Log stuff.
@
text
@d6 1
a6 1
$Log
d21 1
a21 2
#include "misc.h"	/* For |voint| */
#include "heap.h"
d79 1
a79 1
branch(HEAP *tasks,const double lower_bound, const search_node_t *bbnode,
d98 1
a98 1
int branch(HEAP *tasks, const double lower_bound, const search_node_t *bbnode,
d227 1
a227 1
	search_node_t *s1b, *s2a, *s2b, *s3; voint vv;
d285 1
a285 2
		vv.v = s1b;
		HeapInsert(tasks,vv);
d314 1
a314 2
	vv.v = s2b;
	HeapInsert(tasks,vv);
d341 1
a341 2
	vv.v = s3;
	HeapInsert(tasks,vv);
@


1.14
log
@Last revision before depth paper.
@
text
@d1 8
d32 1
a32 1
@@<Exported routines@@>@@;
d98 1
a98 1
@@<Exported routines@@>=
@


1.13
log
@Added threading of from_next_in and to_next_in.
@
text
@d179 1
a179 1
|onetree| array).
d214 4
d223 1
d235 1
a235 1
		s2a->from_next_out = po;
d239 1
a239 1
		s2a->to_next_out = po;
d242 13
d266 1
a266 1
			s1b->from_next_out = po;
d270 1
a270 1
			s1b->to_next_out = po;
d283 3
d312 2
d339 1
a339 1
}
@


1.12
log
@Break ties in best-first search using a depth-first rule.
@
text
@d225 11
a235 1
	/* |s2a->node_num = -2;|	Constraint purposes only */
d243 11
d276 2
a277 1
	{ search_node_t *po;	/* Thread the |from_next_out| and |to_next_out| fields */
d299 2
a300 1
	{ search_node_t *po;	/* Thread the |from_next_out| and |to_next_out| fields */
@


1.11
log
@Corrected some CWEB comment.
@
text
@d36 1
d47 1
d238 1
d254 1
d289 1
@


1.10
log
@Version used for March 17 draft of the fictitious upper bounds paper.
@
text
@d223 1
a223 1
	/* s2a->node_num = -2;	Constraint purposes only */
@


1.9
log
@Complete branch and bound code.  81 SPARC IPC seconds for eil51.tsp
@
text
@d70 1
a70 1
branch(HEAP *PQ,const double lower_bound, const search_node_t *bbnode,
d72 1
a72 1
	const double *lambda, const int method)
d89 1
a89 1
int branch(HEAP *PQ, const double lower_bound, const search_node_t *bbnode,
d215 3
a217 1
	int i;
d223 1
d232 4
a235 4
		if ( method == 0 ) {
			s1b->lambda = new_arr_of(double,n);
			for (i=0;i<n;i++) s1b->lambda[i] =  lambda[i];
		} else s1b->lambda = (double *)lambda;
d237 2
a238 1
		HeapInsert(PQ,vv);
d247 4
a250 4
	if ( method==0 ) {
		s2b->lambda = new_arr_of(double,n);
		for (i=0;i<n;i++) s2b->lambda[i] =  lambda[i];
	} else s2b->lambda = (double *)lambda;
d262 2
a263 1
	HeapInsert(PQ,vv);
d271 2
a272 4
	if ( method == 0 ) {
		s3->lambda = new_arr_of(double,n);
		for (i=0;i<n;i++) s3->lambda[i] =  lambda[i];
	} else s3->lambda = (double *)lambda;
d283 2
d286 2
a287 1
	HeapInsert(PQ,vv);
@
